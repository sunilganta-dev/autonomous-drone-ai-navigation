# üöÄ Autonomous Drone for Intelligent Navigation

## üéØ Objective
The goal of this project is to design and implement a **fully autonomous drone** capable of flying from an origin to a destination **without human control**, while intelligently **avoiding obstacles**, adapting to **environmental conditions** (such as wind, GPS drift, or limited visibility), and making **AI-based flight decisions** in real time.

This project integrates **sensor fusion**, **computer vision**, and **PWM-based control** through a companion computer to achieve safe, efficient, and intelligent flight performance.

---

## ‚öôÔ∏è System Overview

### Core Concept  
To create a drone that can **perceive**, **plan**, and **act** on its own ‚Äî continuously interpreting its surroundings, predicting potential collisions, and dynamically adjusting its flight path to maintain stability and safety.

| **Subsystem** | **Description** |
|----------------|-----------------|
| **Flight Controller** | Cube Orange+ / Pixhawk 6X running ArduPilot or PX4 firmware for low-level stabilization and motor control |
| **Companion Computer** | NVIDIA Jetson Orin NX handling perception, SLAM, object detection, and path planning |
| **Sensors** | GPS, IMU, TF Luna LiDAR, barometer, ultrasonic sensors, and camera modules for navigation and obstacle avoidance |
| **Communication** | MAVLink telemetry over UART connecting the Jetson to the flight controller |
| **Power System** | 4S LiPo battery with LM2596 step-down converter supplying stable power to all onboard components |

---

## üß† Control Logic

- All analog input signals (e.g., sensor readings or trigger inputs) are represented using **PWM (Pulse Width Modulation)** for unified processing.  
- PWM is used for:  
  - **Motor control** through ESCs  
  - **Sensor signal emulation** for analog interfacing  
- **Failsafe Logic:**  
  - Automatic *Return-to-Home (RTH)* or hover behavior on signal loss or low-battery detection  

---

## üß© Development Phases

| **Phase** | **Goal / Deliverable** |
|------------|------------------------|
| **1. Research & Design** | Finalize system architecture, select flight controller, companion computer, and sensors |
| **2. Hardware Assembly** | Mount frame, motors, ESCs, Pixhawk, and Jetson; integrate power distribution and verify PWM output |
| **3. Firmware & Software Setup** | Flash ArduPilot/PX4, configure Mission Planner or QGroundControl, and establish Jetson‚ÄìPixhawk MAVROS communication |
| **4. Sensor Calibration & Testing** | Calibrate IMU, GPS, LiDAR, barometer, and camera modules; validate indoor stability |
| **5. AI Navigation Algorithm** | Implement SLAM, object detection, and path-planning logic on Jetson for autonomous navigation |
| **6. Field Testing & Evaluation** | Perform outdoor test flights, record telemetry, analyze obstacle-avoidance accuracy and failsafe response |
| **7. Documentation & Presentation** | Deliver final report, architecture diagram, and live flight demonstration |

---

## üß≠ System Design Summary

```text
[ LiDAR / Camera / GPS / IMU ]
             ‚Üì
     Sensor Fusion + AI (Jetson)
             ‚Üì MAVLink UART
     Flight Controller (Pixhawk)
             ‚Üì PWM Output
        ESCs ‚Üí Motors ‚Üí Thrust


## Expected Outcomes

- Fully autonomous drone capable of stable, intelligent, and obstacle-aware flight
- Effective sensor fusion integrating LiDAR, GPS, IMU, and visual inputs
- Real-time AI navigation adaptable to varying environmental conditions
- A reproducible open-source framework for future academic and research expansion

## Folder OverView

src/                ‚Üí Core source code (AI, flight, sensors, utilities)
config/             ‚Üí YAML configuration files (ports, PID, AI, calibration)
simulation/         ‚Üí SITL or Gazebo scripts for software-in-the-loop testing
backend/            ‚Üí Flask/FastAPI dashboard for telemetry visualization
notebooks/          ‚Üí Model training, data analysis, and visualization notebooks
docs/               ‚Üí Architecture diagrams and detailed documentation
data/               ‚Üí Image datasets, flight logs, and telemetry data




## Future Vision

- Integration of reinforcement learning for adaptive decision-making
- Advanced multi-sensor fusion (stereo vision + LiDAR + ultrasonic)
- Research on AI-based path optimization and flight efficiency
P- ublish an open-source research framework for educational and academic collaboration Contributors


üë• Contributors
Name	                        Affiliation / Role

Bavani Karthikeyan Janaki   Long Island University, Brooklyn ‚Äî Hardware & System Design
Saicharan Boda	            Long Island University, Brooklyn ‚Äî Flight Control & Testing
Sunil Ganta	                Long Island University, Brooklyn ‚Äî AI & Systems Integration (Recent Graduate)

Supervising Professor:      Dr. Kewei Li, Associate Professor of Computer Science ‚Äî Project Advisor